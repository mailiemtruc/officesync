import uvicorn
import httpx
import datetime
import logging
from typing import Optional, Dict, List
from contextlib import asynccontextmanager
from fastapi import FastAPI
from pydantic import BaseModel
from pydantic_settings import BaseSettings, SettingsConfigDict
import google.generativeai as genai

# Import Manager
from tool_manager import manager
# Import service ng√¥n ng·ªØ
import services.language as lang_service 

# --- C·∫§U H√åNH ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Settings(BaseSettings):
    GOOGLE_API_KEY: str
    ATTENDANCE_SERVICE_URL: str
    
    model_config = SettingsConfigDict(env_file=".env", extra="ignore")

settings = Settings()
genai.configure(api_key=settings.GOOGLE_API_KEY)

# --- B·ªò NH·ªö CHAT (RAM) ---
CHAT_HISTORY: Dict[int, List] = {}

# --- LIFESPAN ---
http_client: Optional[httpx.AsyncClient] = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global http_client
    http_client = httpx.AsyncClient(timeout=30.0)
    yield
    await http_client.aclose()

app = FastAPI(lifespan=lifespan)

class ChatRequest(BaseModel):
    userId: int
    message: str

@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    try:
        # 1. Context c∆° b·∫£n
        today = datetime.date.today()
        service_instructions = manager.get_combined_prompts()
        user_lang = lang_service.USER_PREFERENCES.get(req.userId)
        
        common_rules = """
        QUY T·∫ÆC ·ª®NG X·ª¨:
        1. Th√°i ƒë·ªô: L·ªÖ ph√©p, Nh·∫π nh√†ng, Chuy√™n nghi·ªáp.
        2. ANTI-ROBOT: KH√îNG b·∫Øt ƒë·∫ßu b·∫±ng "OK", "Ok". D√πng "D·∫° v√¢ng", "V√¢ng", "Th∆∞a b·∫°n".
        """

        if not user_lang:
            lang_instruction = f"""
            ‚ö†Ô∏è TR·∫†NG TH√ÅI: Ng∆∞·ªùi d√πng M·ªöI (Ch∆∞a l∆∞u thi·∫øt l·∫≠p ng√¥n ng·ªØ).
            {common_rules}
            
            NHI·ªÜM V·ª§: T·ª± ƒë·ªông nh·∫≠n di·ªán v√† l∆∞u ng√¥n ng·ªØ.

            K·ªäCH B·∫¢N H√ÄNH ƒê·ªòNG:
            1. N·∫øu User CH√ÄO ho·∫∑c n√≥i "START_CONVERSATION":
               -> H·ªèi l·ªãch s·ª±: "B·∫°n mu·ªën giao ti·∫øp b·∫±ng English hay Ti·∫øng Vi·ªát?".
            
            2. N·∫øu User H·ªéI TH·∫≤NG v√†o nghi·ªáp v·ª• (VD: "Ch·∫•m c√¥ng ch∆∞a?", "Attendance history", "T√¥i ƒëi tr·ªÖ kh√¥ng"):
               -> B∆Ø·ªöC 1: Ph√¢n t√≠ch ng√¥n ng·ªØ User ƒëang d√πng (Vietnamese hay English).
               -> B∆Ø·ªöC 2: G·ªåI NGAY tool `set_language` v·ªõi ng√¥n ng·ªØ ƒë√≥. (QUAN TR·ªåNG: Ph·∫£i g·ªçi tool n√†y ƒë·ªÉ h·ªá th·ªëng ghi nh·ªõ).
               -> B∆Ø·ªöC 3: Sau ƒë√≥ m·ªõi g·ªçi ti·∫øp c√°c tool ch·∫•m c√¥ng ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi.
               -> L∆ØU √ù: Kh√¥ng c·∫ßn th√¥ng b√°o "ƒê√£ l∆∞u ng√¥n ng·ªØ", h√£y tr·∫£ l·ªùi th·∫≥ng v√†o c√¢u h·ªèi c·ªßa User.
            
            3. N·∫øu User n√≥i t√™n ng√¥n ng·ªØ (VD: "Ti·∫øng Vi·ªát", "vn", "English"):
               -> G·ªçi `set_language` v√† x√°c nh·∫≠n.
            """
        else:
            if user_lang == "Vietnamese":
                greeting_guide = 'H√£y n√≥i: "Xin ch√†o! Ch√†o m·ª´ng b·∫°n quay tr·ªü l·∫°i OfficeSync. T√¥i c√≥ th·ªÉ h·ªó tr·ª£ g√¨ cho c√¥ng vi·ªác c·ªßa b·∫°n h√¥m nay?"'
            else:
                greeting_guide = 'Say: "Welcome back to OfficeSync! How can I assist you with your work today?"'

            lang_instruction = f"""
            ‚úÖ TR·∫†NG TH√ÅI: Ng√¥n ng·ªØ {user_lang}.
            {common_rules}
            K·ªäCH B·∫¢N:
            - N·∫øu User ch√†o ho·∫∑c n√≥i "START_CONVERSATION" -> {greeting_guide}
            - N·∫øu User ƒëang tr·∫£ l·ªùi c√¢u h·ªèi tr∆∞·ªõc ƒë√≥ (V√≠ d·ª•: "C√≥", "Kh√¥ng", "Chi ti·∫øt ƒëi") -> H√ÉY TI·∫æP T·ª§C M·∫†CH TRUY·ªÜN, ƒê·ª™NG CH√ÄO L·∫†I.
            """

        # 2. System Prompt
        full_system_instruction = f"""
        Th·ªùi gian hi·ªán t·∫°i: {today.strftime('%Y-%m-%d')}.
        B·∫°n l√† tr·ª£ l√Ω ·∫£o OfficeSync.
        
        {lang_instruction}
        
        --- H∆Ø·ªöNG D·∫™N NGHI·ªÜP V·ª§ ---
        {service_instructions}
        """

        # 3. Kh·ªüi t·∫°o Model
        model = genai.GenerativeModel(
            'gemini-2.0-flash', 
            tools=manager.tools_schema,
            system_instruction=full_system_instruction 
        )

        user_history = CHAT_HISTORY.get(req.userId, [])
        chat = model.start_chat(history=user_history, enable_automatic_function_calling=False)

        # 4. G·ª≠i tin nh·∫Øn User
        response = await chat.send_message_async(req.message)

        # --- [S·ª¨A ƒê·ªîI QUAN TR·ªåNG] V√íNG L·∫∂P X·ª¨ L√ù TOOL ---
        # D√πng v√≤ng l·∫∑p ƒë·ªÉ x·ª≠ l√Ω tr∆∞·ªùng h·ª£p Gemini g·ªçi nhi·ªÅu tool li√™n ti·∫øp
        # (VD: set_language -> Xong -> get_attendance -> Xong -> Tr·∫£ l·ªùi text)
        
        final_text = ""
        
        while True:
            function_call_part = None
            if response.candidates and response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if part.function_call:
                        function_call_part = part
                        break
            
            if function_call_part:
                # --- C√ì G·ªåI TOOL ---
                fc = function_call_part.function_call
                tool_name = fc.name
                args = {k: v for k, v in fc.args.items()}
                
                logger.info(f"ü§ñ Tool Call: {tool_name} | Args: {args}")

                # Th·ª±c thi tool
                tool_result = await manager.handle_tool_call(
                    tool_name, req.userId, args, http_client, settings
                )
                
                # G·ª≠i k·∫øt qu·∫£ l·∫°i cho Gemini v√† NH·∫¨N RESPONSE M·ªöI
                response = await chat.send_message_async(
                    genai.protos.Content(
                        parts=[genai.protos.Part(
                            function_response=genai.protos.FunctionResponse(
                                name=tool_name,
                                response={"result": tool_result}
                            )
                        )]
                    )
                )
                # Ti·∫øp t·ª•c v√≤ng l·∫∑p ƒë·ªÉ ki·ªÉm tra xem response m·ªõi c√≥ g·ªçi tool ti·∫øp kh√¥ng
                continue 
            else:
                # --- KH√îNG G·ªåI TOOL (L√† Text) ---
                final_text = response.text
                break # Tho√°t v√≤ng l·∫∑p

        # 6. L∆∞u l·ªãch s·ª≠
        CHAT_HISTORY[req.userId] = chat.history

        return {"reply": final_text}

    except Exception as e:
        logger.error(f"Error: {e}", exc_info=True)
        return {"reply": "Xin l·ªói, h·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë gi√°n ƒëo·∫°n."}

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=5000, reload=True)